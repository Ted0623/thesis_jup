{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of Malginant Mesothelioma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D,Flatten,Dense,Dropout,BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 5]\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, PrecisionRecallDisplay, confusion_matrix, roc_curve, classification_report, auc, plot_roc_curve\n",
    "import time\n",
    "from sklearn import tree\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statistics\n",
    "from lightgbm import LGBMClassifier, plot_importance\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler, StandardScaler, RobustScaler, QuantileTransformer, LabelEncoder\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.feature_selection import SelectFromModel, RFECV, RFE, SelectKBest, chi2, f_classif, mutual_info_classif, SelectKBest\n",
    "import shap\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate, cross_val_predict\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "This section will look into the correlation between continuous variables via. a heatmap, the distribution of the variables, and the boxplot of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesdata = pd.read_excel(r'C:/Users/tedch/Documents/Thesis/mesdata.xlsx')\n",
    "X=mesdata\n",
    "y=mesdata['class of diagnosis']\n",
    "transform=['duration of symptoms', 'platelet count (PLT)', 'alkaline phosphatise (ALP)', 'glucose',\n",
    "           'pleural lactic dehydrogenise', 'cell count (WBC)', 'blood lactic dehydrogenise (LDH)']\n",
    "X[transform]=X[transform].apply(np.log)\n",
    "\n",
    "num_feat=['age','duration of asbestos exposure', 'duration of symptoms', 'white blood', 'cell count (WBC)',\n",
    "          'platelet count (PLT)', 'sedimentation', 'blood lactic dehydrogenise (LDH)', 'alkaline phosphatise (ALP)',\n",
    "          'total protein', 'albumin', 'glucose', 'pleural lactic dehydrogenise', 'pleural albumin',\n",
    "          'pleural glucose', 'C-reactive protein (CRP)' , 'pleural protein']\n",
    "\n",
    "cat_feat=['gender', 'city', 'asbestos exposure', 'type of MM', 'diagnosis method',\n",
    "       'keep side', 'cytology', 'dyspnoea', 'ache on chest', 'weakness',\n",
    "       'habit of cigarette', 'performance status', 'hemoglobin (HGB)',\n",
    "       'dead or not', 'pleural effusion', 'pleural thickness on tomography',\n",
    "       'pleural level of acidity (pH)', 'class of diagnosis']\n",
    "\n",
    "X_num = X[num_feat]\n",
    "X_cat = X[cat_feat]\n",
    "\n",
    "# Corr heatmap\n",
    "\n",
    "corr = X_num.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(\n",
    "    data=X_num.corr(), annot=True, mask=mask, cmap=cmap\n",
    ")\n",
    "\n",
    "print('Number of missing values:\\n', X.isnull().sum())\n",
    "print('Number of duplicates:',X.duplicated().sum())\n",
    "X_num.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Num features summary\n",
    "\n",
    "#X_num.hist(figsize=(6, 3))\n",
    "\n",
    "fig, ax = plt.subplots(6, 3, figsize=(20, 20))\n",
    "for ax, feature in zip(ax.flat, X_num.columns):\n",
    "    sns.histplot(X_num[feature], ax=ax)\n",
    "\n",
    "# Cat features summary\n",
    "fig, ax = plt.subplots(3, 6, figsize=(20, 10))\n",
    "for variable, subplot in zip(cat_feat, ax.flatten()):\n",
    "    sns.countplot(mesdata[variable], ax=subplot, data=mesdata, hue='class of diagnosis')\n",
    "    for label in subplot.get_xticklabels():\n",
    "        label.set_rotation(90)\n",
    "\n",
    "chisqvar = ['gender', 'type of MM', 'diagnosis method', 'keep side', 'class of diagnosis']\n",
    "\n",
    "f, axes = plt.subplots(1,4)\n",
    "sns.countplot(mesdata['gender'], data=mesdata, hue='class of diagnosis', ax=axes[0])\n",
    "sns.countplot(mesdata['type of MM'], data=mesdata, hue='class of diagnosis', ax=axes[1])\n",
    "sns.countplot(mesdata['diagnosis method'], data=mesdata, hue='class of diagnosis', ax=axes[2])\n",
    "sns.countplot(mesdata['keep side'], data=mesdata, hue='class of diagnosis', ax=axes[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Target Summary\n",
    "mesdata.groupby('class of diagnosis').size().plot(kind='pie', autopct='%.2f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"class of diagnosis\", data=mesdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Outliers Scatter\n",
    "sns.set_theme(style=\"ticks\")\n",
    "sns.pairplot(mesdata, y_vars=X_num.iloc[:,0:6], x_vars=X_num.iloc[:,0:6], hue='class of diagnosis')\n",
    "sns.pairplot(mesdata, y_vars=X_num.iloc[:,6:12], x_vars=X_num.iloc[:,6:12], hue='class of diagnosis')\n",
    "sns.pairplot(mesdata, y_vars=X_num.iloc[:,12:], x_vars=X_num.iloc[:,12:], hue='class of diagnosis')\n",
    "sns.pairplot(mesdata, y_vars=['class of diagnosis'], x_vars=X_num.iloc[:,0:6], hue='class of diagnosis')\n",
    "sns.pairplot(mesdata, y_vars=['class of diagnosis'], x_vars=X_num.iloc[:,6:12], hue='class of diagnosis')\n",
    "sns.pairplot(mesdata, y_vars=['class of diagnosis'], x_vars=X_num.iloc[:,12:], hue='class of diagnosis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "f, axes = plt.subplots(1,5)\n",
    "sns.boxplot(y=X_num.iloc[:,0], x=y, data=X_num, orient='v', ax=axes[0])\n",
    "sns.boxplot(y=X_num.iloc[:,1], x=y, data=X_num, orient='v', ax=axes[1])\n",
    "sns.boxplot(y=X_num.iloc[:,2], x=y, data=X_num, orient='v', ax=axes[2])\n",
    "sns.boxplot(y=X_num.iloc[:,3], x=y, data=X_num, orient='v', ax=axes[3])\n",
    "sns.boxplot(y=X_num.iloc[:,4], x=y, data=X_num, orient='v', ax=axes[4])\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(1,5)\n",
    "sns.boxplot(y=X_num.iloc[:,5], x=y, data=X_num, orient='v', ax=axes[0])\n",
    "sns.boxplot(y=X_num.iloc[:,6], x=y, data=X_num, orient='v', ax=axes[1])\n",
    "sns.boxplot(y=X_num.iloc[:,7], x=y, data=X_num, orient='v', ax=axes[2])\n",
    "sns.boxplot(y=X_num.iloc[:,8], x=y, data=X_num, orient='v', ax=axes[3])\n",
    "sns.boxplot(y=X_num.iloc[:,9], x=y, data=X_num, orient='v', ax=axes[4])\n",
    "\n",
    "f, axes = plt.subplots(1,5)\n",
    "sns.boxplot(y=X_num.iloc[:,10], x=y, data=X_num, orient='v', ax=axes[0])\n",
    "sns.boxplot(y=X_num.iloc[:,11], x=y, data=X_num, orient='v', ax=axes[1])\n",
    "sns.boxplot(y=X_num.iloc[:,12], x=y, data=X_num, orient='v', ax=axes[2])\n",
    "sns.boxplot(y=X_num.iloc[:,13], x=y, data=X_num, orient='v', ax=axes[3])\n",
    "sns.boxplot(y=X_num.iloc[:,14], x=y, data=X_num, orient='v', ax=axes[4])\n",
    "\n",
    "f, axes = plt.subplots(1,2)\n",
    "sns.boxplot(y=X_num.iloc[:,15], x=y, data=X_num, orient='v', ax=axes[0])\n",
    "sns.boxplot(y=X_num.iloc[:,16], x=y, data=X_num, orient='v', ax=axes[1])\n",
    "\n",
    "f, axes = plt.subplots(1,2)\n",
    "sns.boxplot(y=mesdata['age'], x=y, data=mesdata, orient='v', ax=axes[0])\n",
    "sns.boxplot(y=mesdata['C-reactive protein (CRP)'], x=y, data=mesdata, orient='v', ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data and Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "# Transform\n",
    "mesdata = pd.read_excel(r'C:/Users/tedch/Documents/Thesis/mesdata.xlsx')\n",
    "mesdata = mesdata.rename(columns={'class of diagnosis': 'diagnosis'})\n",
    "mesdata.diagnosis.replace({1:0,2:1},inplace=True)\n",
    "y=mesdata.diagnosis\n",
    "X=mesdata.drop(['diagnosis', 'diagnosis method', 'pleural protein'],axis=1)\n",
    "transform=['duration of symptoms', 'platelet count (PLT)', 'alkaline phosphatise (ALP)', 'glucose',\n",
    "           'pleural lactic dehydrogenise', 'cell count (WBC)', 'blood lactic dehydrogenise (LDH)']\n",
    "X[transform]=X[transform].apply(np.log)\n",
    "feature_names = list(X.columns)\n",
    "\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y, shuffle=True, test_size=0.2, random_state=42)\n",
    "\n",
    "\"\"\" sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "oversample = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "X_train, y_train= oversample.fit_resample(X_train, y_train) \"\"\"\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score),\n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score),\n",
    "           'f1_score' : make_scorer(f1_score),\n",
    "           #'roc_auc' : make_scorer(roc_auc_score)\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Function to Get the Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(scores):\n",
    "    scoredict={\n",
    "        'accuracy' : np.mean(scores.get('test_accuracy'))*100,\n",
    "        'recall' : np.mean(scores.get('test_recall'))*100,\n",
    "        'precision' : np.mean(scores.get('test_precision'))*100,\n",
    "        'f1-score' : np.mean(scores.get('test_f1_score'))*100,\n",
    "        #'roc_auc' : np.mean(scores.get('test_roc_auc'))*100\n",
    "    }\n",
    "    print(scoredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "tensorflow.random.set_seed(110)\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    #model.add(Dense(units=16, activation='relu'))\n",
    "    #model.add(Dense(units=8, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model=KerasClassifier(build_fn=create_model, epochs=150, batch_size=32, verbose=0)\n",
    "history = model.fit(X_train,y_train,batch_size=32,epochs=150,verbose=0,validation_data=(X_test,y_test))\n",
    "\n",
    "\n",
    "# Scores\n",
    "start_time = time.time()\n",
    "scores = cross_validate(model, X_train, y_train, cv=7, scoring=scoring)\n",
    "print(\"--- %s seconds ---\" % ((time.time() - start_time)/7))\n",
    "\n",
    "get_scores(scores)\n",
    "\n",
    "\n",
    "# Loss graph\n",
    "\n",
    "epochs=150\n",
    "\n",
    "epochRange = range(1,epochs+1)\n",
    "plt.plot(epochRange,history.history['accuracy'])\n",
    "plt.plot(epochRange,history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train','Validation'],loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochRange,history.history['loss'])\n",
    "plt.plot(epochRange,history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train','Validation'],loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Design\n",
    "The pipeline is based on imblearn's pipeline design as we have unbalanced data and so it would be ideal to use an oversampling technique. Pre-processing steps should be applied before any over/undersampling methods as sampling methods require a simple model to be trained and perform better on pre-processed data. \n",
    "\n",
    "For k-NN classifiers, the value of p can be changed to 1 or 2 with 1 being Manhattan distance and 2 being Euclidean distance.\n",
    "\n",
    "The penalty of the logistic regression model can be changed to eitehr L1 for Lasso or L2 for ridge. There is also a model for elastic net penalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR\n",
    "lr=LogisticRegression(random_state=42, class_weight='balanced')\n",
    "lrp=LogisticRegression(random_state=42, class_weight='balanced',penalty='l1',solver='liblinear')\n",
    "lre=LogisticRegression(random_state=42, class_weight='balanced', solver='saga', l1_ratio=0.5, penalty='elasticnet')\n",
    "\n",
    "# Decision Trees\n",
    "rf = RandomForestClassifier(random_state=42, oob_score=True)\n",
    "knn = KNeighborsClassifier(n_neighbors=1, p=1)\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=42)\n",
    "lgb = LGBMClassifier(random_state=42)\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "cart=tree.DecisionTreeClassifier(random_state=42,class_weight='balanced')\n",
    "\n",
    "# ANN\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    #model.add(Dense(units=16, activation='relu'))\n",
    "    #model.add(Dense(units=8, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "ann=KerasClassifier(build_fn=create_model, epochs=150, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=7\n",
    "\n",
    "def pipe(clf,cv):\n",
    "    pipeline = Pipeline([\n",
    "                    ('scale', StandardScaler()),\n",
    "                    ('oversample', SMOTE(sampling_strategy='minority', random_state=42)),\n",
    "                    ('clf', clf)\n",
    "                    ])\n",
    "    scores=cross_validate(pipeline, X_train, y_train, cv=cv, scoring=scoring)\n",
    "    return(get_scores(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002597894A0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000259786DDB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "{'accuracy': 66.02316602316601, 'recall': 35.837495837495844, 'precision': 42.66483516483516, 'f1-score': 38.14156509285636}\n"
     ]
    }
   ],
   "source": [
    "pipe(ann,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e8901ad9e28f1de3770652873e5de76a25bd2fe8436a3bfc64bcd9233978153"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
